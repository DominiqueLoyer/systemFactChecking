#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
üî¨ SysCRED TREC DEMONSTRATION
==============================
D√©monstration des capacit√©s TREC int√©gr√©es dans SysCRED.
"""

import sys
import time

def main():
    print("=" * 70)
    print("üî¨ SysCRED TREC DEMONSTRATION - Localhost")
    print("=" * 70)
    print()

    # 1. Import des modules TREC (direct, sans charger les mod√®les ML)
    print("üì¶ 1. Chargement des modules TREC...")
    import sys
    sys.path.insert(0, '.')
    
    # Import direct pour √©viter le chargement des mod√®les ML
    from syscred.trec_retriever import TRECRetriever, Evidence
    from syscred.trec_dataset import TRECDataset, TRECTopic
    from syscred.eval_metrics import EvaluationMetrics
    from syscred.ir_engine import IREngine
    
    # Sample topics d√©finis localement
    SAMPLE_TOPICS = {
        "51": TRECTopic(
            topic_id="51",
            title="Airbus Subsidies",
            description="How much government money has been used to support Airbus?",
            narrative="A relevant document discusses subsidies to Airbus."
        ),
        "52": TRECTopic(
            topic_id="52", 
            title="Smoking bans",
            description="What are the effects of smoking bans in public places?",
            narrative="Relevant documents discuss smoking restrictions."
        ),
        "53": TRECTopic(
            topic_id="53",
            title="Endangered species",
            description="What species are currently endangered?",
            narrative="Documents about endangered wildlife."
        ),
    }
    
    print("   ‚úÖ Tous les modules charg√©s avec succ√®s!")
    print()

    # 2. Initialisation du retriever
    print("üîß 2. Initialisation du TRECRetriever...")
    retriever = TRECRetriever(use_stemming=True, enable_prf=False)
    print("   ‚úÖ Retriever initialis√© (mode in-memory, stemming=True)")
    print()

    # 3. Ajout d'un corpus de d√©monstration
    print("üìö 3. Cr√©ation d'un corpus de d√©monstration (style AP88-90)...")
    retriever.corpus = {
        "AP880101-0001": {
            "text": "Climate change is primarily caused by human activities, particularly the burning of fossil fuels which release greenhouse gases into the atmosphere.",
            "title": "Climate Science Report"
        },
        "AP880101-0002": {
            "text": "The Earth's temperature has risen significantly over the past century due to greenhouse gas emissions from industrial activities and deforestation.",
            "title": "Global Warming Study"
        },
        "AP880102-0001": {
            "text": "Scientists warn that sea levels could rise dramatically if current warming trends continue, threatening coastal cities worldwide.",
            "title": "Sea Level Warning"
        },
        "AP890215-0001": {
            "text": "The presidential election campaign focused on economic policies, healthcare reform, and national security issues.",
            "title": "Election Coverage"
        },
        "AP890216-0001": {
            "text": "Stock markets rose sharply after positive economic indicators were released by the Federal Reserve, signaling economic recovery.",
            "title": "Financial News"
        },
    }
    print(f"   ‚úÖ Corpus charg√©: {len(retriever.corpus)} documents")
    for doc_id, doc in retriever.corpus.items():
        print(f"      - {doc_id}: {doc['title']}")
    print()

    # 4. D√©monstration de r√©cup√©ration d'√©vidences
    print("=" * 70)
    print("üîç 4. D√âMONSTRATION: R√©cup√©ration d'√©vidences pour un claim")
    print("=" * 70)
    print()
    
    claims = [
        "Climate change is caused by human activities",
        "The stock market is influenced by economic indicators",
        "Sea levels are rising due to global warming"
    ]
    
    for i, claim in enumerate(claims, 1):
        print(f"   üìù Claim #{i}: \"{claim}\"")
        print()
        
        result = retriever.retrieve_evidence(claim=claim, k=3)
        
        print(f"   ‚è±Ô∏è  Temps de recherche: {result.search_time_ms:.2f} ms")
        print(f"   üìä R√©sultats trouv√©s: {result.total_retrieved}")
        print()
        
        for evidence in result.evidences:
            print(f"      Rank {evidence.rank} | Score: {evidence.score:.4f}")
            print(f"      üìÑ Doc: {evidence.doc_id}")
            print(f"      üìù {evidence.text[:80]}...")
            print()
        
        print("-" * 70)
        print()

    # 5. D√©monstration des m√©triques IR
    print("=" * 70)
    print("üìä 5. D√âMONSTRATION: M√©triques d'√©valuation IR")
    print("=" * 70)
    print()
    
    metrics = EvaluationMetrics()
    
    # Simulation d'un run TREC
    retrieved = ["AP880101-0001", "AP890215-0001", "AP880101-0002", "AP880102-0001", "AP890216-0001"]
    relevant = {"AP880101-0001", "AP880101-0002", "AP880102-0001"}  # Documents sur le climat
    
    print("   üìã Simulation d'√©valuation TREC:")
    print(f"      Documents r√©cup√©r√©s: {retrieved}")
    print(f"      Documents pertinents: {relevant}")
    print()
    
    p_at_3 = metrics.precision_at_k(retrieved, relevant, k=3)
    p_at_5 = metrics.precision_at_k(retrieved, relevant, k=5)
    r_at_5 = metrics.recall_at_k(retrieved, relevant, k=5)
    ap = metrics.average_precision(retrieved, relevant)
    rr = metrics.reciprocal_rank(retrieved, relevant)
    
    print("   üìà M√©triques calcul√©es:")
    print(f"      ‚Ä¢ P@3 (Precision at 3):     {p_at_3:.4f}")
    print(f"      ‚Ä¢ P@5 (Precision at 5):     {p_at_5:.4f}")
    print(f"      ‚Ä¢ R@5 (Recall at 5):        {r_at_5:.4f}")
    print(f"      ‚Ä¢ AP (Average Precision):  {ap:.4f}")
    print(f"      ‚Ä¢ RR (Reciprocal Rank):    {rr:.4f}")
    print()

    # 6. D√©monstration des topics TREC
    print("=" * 70)
    print("üìã 6. D√âMONSTRATION: Topics TREC (AP88-90 samples)")
    print("=" * 70)
    print()
    
    print(f"   üìö {len(SAMPLE_TOPICS)} topics √©chantillons disponibles:")
    print()
    for topic_id, topic in list(SAMPLE_TOPICS.items())[:3]:
        print(f"   Topic {topic_id}:")
        print(f"      Title: {topic.title}")
        print(f"      Description: {topic.description[:60]}...")
        print()

    # 7. D√©monstration du pr√©processeur IR
    print("=" * 70)
    print("üî§ 7. D√âMONSTRATION: Pr√©processeur IR (stemming + stopwords)")
    print("=" * 70)
    print()
    
    engine = IREngine(use_stemming=True)
    
    test_texts = [
        "The quick brown fox jumps over the lazy dog",
        "Climate change is affecting global temperatures",
        "Information Retrieval systems are important"
    ]
    
    for text in test_texts:
        processed = engine.preprocess(text)
        print(f"   Original:  \"{text}\"")
        print(f"   Processed: \"{processed}\"")
        print()

    # 8. Statistiques finales
    print("=" * 70)
    print("üìä 8. Statistiques du retriever")
    print("=" * 70)
    print()
    
    stats = retriever.get_statistics()
    for key, value in stats.items():
        print(f"   ‚Ä¢ {key}: {value}")
    print()

    print("=" * 70)
    print("‚úÖ D√âMONSTRATION TERMIN√âE")
    print("=" * 70)
    print()
    print("Les modules TREC sont pr√™ts pour l'int√©gration fact-checking!")
    print("Lancez le serveur avec: python -m syscred.backend_app")
    print()


if __name__ == "__main__":
    main()
