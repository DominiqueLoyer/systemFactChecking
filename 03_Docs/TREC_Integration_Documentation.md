# üìö Documentation: Int√©gration TREC AP88-90 dans SysCRED

**Auteur:** Dominique S. Loyer  
**Date:** 2 f√©vrier 2026  
**Version:** 2.3  
**Citation Key:** loyerEvaluationModelesRecherche2025

---

## üìñ Table des mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Qu'est-ce que TREC AP88-90?](#quest-ce-que-trec-ap88-90)
3. [Architecture du module](#architecture-du-module)
4. [Les m√©triques IR expliqu√©es](#les-m√©triques-ir-expliqu√©es)
5. [Comment fonctionne la recherche d'√©vidences](#comment-fonctionne-la-recherche-d√©vidences)
6. [API Endpoints](#api-endpoints)
7. [Exemples d'utilisation](#exemples-dutilisation)
8. [Int√©gration avec SysCRED](#int√©gration-avec-syscred)

---

## Vue d'ensemble

Le module TREC int√®gre des capacit√©s de **Recherche d'Information (IR)** dans SysCRED, permettant de :

1. **Rechercher des √©vidences** pour v√©rifier des affirmations (claims)
2. **Calculer des m√©triques d'√©valuation** standardis√©es (MAP, NDCG, P@K)
3. **Utiliser diff√©rents mod√®les de scoring** : BM25, TF-IDF, QLD

Cette int√©gration repose sur la m√©thodologie **TREC (Text REtrieval Conference)**, le standard de r√©f√©rence en √©valuation de syst√®mes de recherche d'information.

---

## Qu'est-ce que TREC AP88-90?

### üì∞ Le corpus Associated Press (AP)

Le corpus **AP88-90** est une collection de **242 918 articles** de l'Associated Press publi√©s entre 1988 et 1990. C'est l'un des corpus les plus utilis√©s dans la recherche en IR.

| Caract√©ristique | Valeur |
|----------------|--------|
| Source | Associated Press (agence de presse) |
| P√©riode | 1988-1990 |
| Nombre de documents | 242 918 |
| Format | SGML/XML avec balises `<DOC>`, `<DOCNO>`, `<TEXT>` |
| Langue | Anglais |

### üéØ Les Topics (requ√™tes)

Les topics TREC sont des **requ√™tes structur√©es** avec :
- **Title** : Version courte (2-4 mots)
- **Description** : Phrase d√©crivant le besoin d'information
- **Narrative** : Crit√®res d√©taill√©s de pertinence

**Exemple de topic :**
```xml
<top>
  <num>51</num>
  <title>Airbus Subsidies</title>
  <desc>How have the European governments subsidized Airbus?</desc>
  <narr>A relevant document will discuss European governmental 
  subsidies to Airbus Industrie...</narr>
</top>
```

### ‚úì Les Qrels (jugements de pertinence)

Les **qrels** (Query RELevance judgments) sont les jugements humains de pertinence :
```
topic_id  0  doc_id  relevance
51        0  AP880212-0001  1
51        0  AP880304-0035  0
```

---

## Architecture du module

```
syscred/
‚îú‚îÄ‚îÄ trec_retriever.py    # üîç Recherche d'√©vidences
‚îú‚îÄ‚îÄ trec_dataset.py      # üìö Gestion du corpus TREC
‚îú‚îÄ‚îÄ ir_engine.py         # ‚öôÔ∏è Moteur IR (BM25, TF-IDF, QLD)
‚îú‚îÄ‚îÄ eval_metrics.py      # üìä M√©triques d'√©valuation
‚îî‚îÄ‚îÄ backend_app.py       # üåê Endpoints API (int√©gr√©)
```

### D√©pendances entre modules

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     backend_app.py                          ‚îÇ
‚îÇ                    (API REST Flask)                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ               ‚îÇ               ‚îÇ
         ‚ñº               ‚ñº               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   TREC      ‚îÇ  ‚îÇ    IR       ‚îÇ  ‚îÇ  Eval       ‚îÇ
‚îÇ  Retriever  ‚îÇ  ‚îÇ   Engine    ‚îÇ  ‚îÇ  Metrics    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ               ‚îÇ
         ‚îÇ               ‚îÇ
         ‚ñº               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ    TREC     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ   Dataset   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Les m√©triques IR expliqu√©es

### üìä Comprendre l'interface de d√©mo

Dans la capture d'√©cran de l'interface TREC Demo, vous voyez :

```
üìä M√©triques IR
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  P@3    ‚îÇ   MAP   ‚îÇ   MRR   ‚îÇ
‚îÇ  0.67   ‚îÇ  0.81   ‚îÇ  1.00   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Ces m√©triques sont calcul√©es sur un exemple de d√©monstration :**

| √âl√©ments | Valeur |
|----------|--------|
| Documents r√©cup√©r√©s | ["AP880101-0001", "AP890215-0001", "AP880101-0002"] |
| Documents pertinents | ["AP880101-0001", "AP880101-0002", "AP880102-0001"] |
| K (nombre de r√©sultats) | 3 |

### üìê P@K (Precision at K) = 0.67

**D√©finition :** Proportion de documents pertinents parmi les K premiers r√©cup√©r√©s.

**Formule :**
$$P@K = \frac{|\text{pertinents} \cap \text{r√©cup√©r√©s}[:K]|}{K}$$

**Calcul :**
- R√©cup√©r√©s (top 3) : AP880101-0001 ‚úì, AP890215-0001 ‚úó, AP880101-0002 ‚úì
- Pertinents trouv√©s : 2 sur 3
- **P@3 = 2/3 = 0.67**

**Interpr√©tation :** 67% des 3 premiers documents sont pertinents.

---

### üìê MAP (Mean Average Precision) = 0.81

**D√©finition :** Moyenne des pr√©cisions calcul√©es √† chaque document pertinent.

**Formule :**
$$MAP = \frac{1}{|R|} \sum_{k=1}^{n} P(k) \times rel(k)$$

o√π $rel(k) = 1$ si le document au rang $k$ est pertinent.

**Calcul d√©taill√© :**
1. Rang 1 (AP880101-0001) : pertinent ‚úì ‚Üí P@1 = 1/1 = 1.00
2. Rang 2 (AP890215-0001) : non pertinent ‚úó ‚Üí ignor√©
3. Rang 3 (AP880101-0002) : pertinent ‚úì ‚Üí P@3 = 2/3 = 0.67

$$AP = \frac{1.00 + 0.67}{2} = 0.835 \approx 0.81$$

**Interpr√©tation :** Qualit√© globale du ranking. Plus les documents pertinents sont en haut, plus le MAP est √©lev√©.

---

### üìê MRR (Mean Reciprocal Rank) = 1.00

**D√©finition :** Inverse du rang du premier document pertinent.

**Formule :**
$$MRR = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \frac{1}{rank_i}$$

**Calcul :**
- Premier document pertinent : AP880101-0001 (rang 1)
- **MRR = 1/1 = 1.00**

**Interpr√©tation :** Le premier document pertinent est en position 1 (optimal).

---

### üìê NDCG (Normalized Discounted Cumulative Gain)

**D√©finition :** Mesure la qualit√© du ranking avec p√©nalit√© logarithmique pour les rangs inf√©rieurs.

**Formule :**
$$DCG@K = \sum_{i=1}^{K} \frac{2^{rel_i} - 1}{\log_2(i+1)}$$

$$NDCG@K = \frac{DCG@K}{IDCG@K}$$

o√π IDCG est le DCG du ranking parfait.

**Interpr√©tation :** 1.0 = ranking parfait, 0.0 = aucun document pertinent en haut.

---

### üìê Recall@K (Rappel)

**D√©finition :** Proportion de documents pertinents r√©cup√©r√©s parmi tous les pertinents.

**Formule :**
$$R@K = \frac{|\text{pertinents} \cap \text{r√©cup√©r√©s}[:K]|}{|\text{pertinents}|}$$

**Calcul :**
- Total pertinents : 3 (AP880101-0001, AP880101-0002, AP880102-0001)
- R√©cup√©r√©s et pertinents : 2
- **R@3 = 2/3 = 0.67**

---

## Comment fonctionne la recherche d'√©vidences

### üîç Pipeline de recherche

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Claim (requ√™te)                           ‚îÇ
‚îÇ         "Climate change is caused by humans"                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   1. Pr√©traitement                           ‚îÇ
‚îÇ  ‚Ä¢ Tokenization (d√©coupage en mots)                          ‚îÇ
‚îÇ  ‚Ä¢ Suppression des stopwords (the, is, by...)                ‚îÇ
‚îÇ  ‚Ä¢ Stemming Porter (caused ‚Üí caus, humans ‚Üí human)           ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  R√©sultat: ["climat", "chang", "caus", "human"]              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   2. Scoring BM25                            ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  BM25(D,Q) = Œ£ IDF(qi) √ó [f(qi,D) √ó (k1+1)]                 ‚îÇ
‚îÇ              ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                ‚îÇ
‚îÇ              f(qi,D) + k1 √ó (1-b+b√ó|D|/avgdl)               ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  Param√®tres optimis√©s sur AP88-90:                           ‚îÇ
‚îÇ  ‚Ä¢ k1 = 0.9 (saturation des termes)                          ‚îÇ
‚îÇ  ‚Ä¢ b = 0.4 (normalisation longueur)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   3. Ranking des r√©sultats                   ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  Rank 1: AP880101-0001 (score: 6.27) ‚Üê "Climate change..."   ‚îÇ
‚îÇ  Rank 2: AP880101-0002 (score: 3.93) ‚Üê "Earth's temperature" ‚îÇ
‚îÇ  Rank 3: AP880102-0001 (score: 4.11) ‚Üê "Sea levels..."       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### ‚öôÔ∏è Mod√®les de scoring disponibles

| Mod√®le | Description | Usage recommand√© |
|--------|-------------|------------------|
| **BM25** | Best Match 25, standard TREC | Par d√©faut, meilleur pour requ√™tes courtes |
| **TF-IDF** | Term Frequency √ó Inverse Document Frequency | Recherche classique |
| **QLD** | Query Likelihood (Dirichlet) | Mod√®le probabiliste de langue |

---

## API Endpoints

### POST `/api/trec/search`

Recherche d'√©vidences pour une affirmation.

**Requ√™te :**
```json
{
  "query": "Climate change is caused by humans",
  "k": 10,
  "model": "bm25"
}
```

**R√©ponse :**
```json
{
  "query": "Climate change is caused by humans",
  "results": [
    {
      "doc_id": "AP880101-0001",
      "score": 6.2745,
      "rank": 1,
      "text": "Climate change is primarily caused by human activities...",
      "title": "Climate Science Report",
      "model": "bm25"
    }
  ],
  "total": 3,
  "model": "bm25",
  "search_time_ms": 12.5
}
```

---

### POST `/api/trec/metrics`

Calcule les m√©triques IR pour un r√©sultat de recherche.

**Requ√™te :**
```json
{
  "retrieved": ["AP880101-0001", "AP890215-0001", "AP880101-0002"],
  "relevant": ["AP880101-0001", "AP880101-0002", "AP880102-0001"]
}
```

**R√©ponse :**
```json
{
  "precision_at_3": 0.6667,
  "recall_at_3": 0.6667,
  "average_precision": 0.8125,
  "mrr": 1.0,
  "ndcg_at_3": 0.8789,
  "metrics_explanation": {
    "P@K": "Proportion de documents pertinents parmi les K premiers r√©cup√©r√©s",
    "R@K": "Proportion de documents pertinents r√©cup√©r√©s parmi tous les pertinents",
    "AP": "Moyenne des pr√©cisions √† chaque document pertinent trouv√©",
    "MRR": "Rang r√©ciproque du premier document pertinent",
    "NDCG": "Gain cumulatif normalis√© avec d√©croissance logarithmique"
  }
}
```

---

### GET `/api/trec/corpus`

Retourne les informations du corpus de d√©monstration.

**R√©ponse :**
```json
{
  "corpus_size": 7,
  "corpus_type": "AP88-90 Demo",
  "documents": [
    {
      "doc_id": "AP880101-0001",
      "title": "Climate Science Report",
      "text_preview": "Climate change is primarily caused by human activities..."
    }
  ]
}
```

---

### GET `/api/trec/health`

V√©rifie l'√©tat du module TREC.

**R√©ponse :**
```json
{
  "status": "healthy",
  "trec_available": true,
  "retriever_initialized": true,
  "corpus_size": 7,
  "models_available": ["bm25", "tfidf", "qld"]
}
```

---

## Exemples d'utilisation

### Python (requests)

```python
import requests

# Recherche d'√©vidences
response = requests.post('http://localhost:5001/api/trec/search', json={
    'query': 'Climate change is caused by humans',
    'k': 5,
    'model': 'bm25'
})

results = response.json()
for r in results['results']:
    print(f"[{r['rank']}] {r['doc_id']} (score: {r['score']:.4f})")
    print(f"    {r['text'][:80]}...")
```

### cURL

```bash
# Recherche
curl -X POST http://localhost:5001/api/trec/search \
  -H "Content-Type: application/json" \
  -d '{"query": "global warming effects", "k": 3}'

# M√©triques
curl -X POST http://localhost:5001/api/trec/metrics \
  -H "Content-Type: application/json" \
  -d '{"retrieved": ["doc1", "doc2"], "relevant": ["doc1", "doc3"]}'
```

### JavaScript (Fetch)

```javascript
const response = await fetch('/api/trec/search', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    query: 'renewable energy alternatives',
    k: 10
  })
});

const data = await response.json();
console.log(`Found ${data.total} results in ${data.search_time_ms}ms`);
```

---

## Int√©gration avec SysCRED

### üîó Pipeline de fact-checking avec TREC

Le module TREC s'int√®gre dans le pipeline de v√©rification :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Claim (entr√©e)                           ‚îÇ
‚îÇ            "Le changement climatique est caus√© par l'homme"     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                               ‚îÇ
              ‚ñº                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   TREC Evidence         ‚îÇ    ‚îÇ    External APIs                ‚îÇ
‚îÇ   Retrieval             ‚îÇ    ‚îÇ    (Google Fact Check,          ‚îÇ
‚îÇ   (/api/trec/search)    ‚îÇ    ‚îÇ     Wikipedia, etc.)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ                               ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Evidence Aggregation                         ‚îÇ
‚îÇ  ‚Ä¢ Combinaison des √©vidences trouv√©es                           ‚îÇ
‚îÇ  ‚Ä¢ Scoring de pertinence                                        ‚îÇ
‚îÇ  ‚Ä¢ Classification du support/r√©futation                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 Verdict Generation                              ‚îÇ
‚îÇ  ‚Ä¢ SUPPORTS / REFUTES / NOT ENOUGH INFO                         ‚îÇ
‚îÇ  ‚Ä¢ Score de cr√©dibilit√©                                         ‚îÇ
‚îÇ  ‚Ä¢ Explication textuelle                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### M√©thode `verify_with_evidence()`

Dans `verification_system.py`, la nouvelle m√©thode combine TREC avec la v√©rification :

```python
def verify_with_evidence(self, claim: str, k: int = 5) -> Dict[str, Any]:
    """
    Complete fact-checking pipeline with evidence retrieval.
    
    1. Retrieve evidence using TREC
    2. Analyze evidence for support/refutation
    3. Generate verdict
    """
    # 1. Retrieve evidence
    retrieval_result = self.retrieve_evidence(claim, k=k)
    
    # 2. Analyze evidence
    evidences = retrieval_result.evidences
    supporting = [e for e in evidences if e.score > 5.0]
    
    # 3. Generate verdict
    if len(supporting) >= 2:
        verdict = "SUPPORTS"
        confidence = 0.8
    elif len(supporting) >= 1:
        verdict = "LIKELY_SUPPORTS"
        confidence = 0.6
    else:
        verdict = "NOT_ENOUGH_INFO"
        confidence = 0.3
    
    return {
        "claim": claim,
        "verdict": verdict,
        "confidence": confidence,
        "evidences": [e.to_dict() for e in evidences[:3]]
    }
```

---

## R√©f√©rences

1. **TREC (Text REtrieval Conference)**  
   [https://trec.nist.gov/](https://trec.nist.gov/)

2. **AP Corpus**  
   Harman, D. (1993). "Overview of TREC-1." NIST Special Publication 500-207.

3. **BM25**  
   Robertson, S. E., & Walker, S. (1994). "Some simple effective approximations to the 2-Poisson model."

4. **pytrec_eval**  
   [https://github.com/cvangysel/pytrec_eval](https://github.com/cvangysel/pytrec_eval)

5. **Loyer, D. S. (2025)**  
   "√âvaluation des mod√®les de recherche d'information sur le corpus TREC AP88-90."
   (loyerEvaluationModelesRecherche2025)

---

## üîÑ Recommandations pour reprendre le travail

### √âtat actuel (2 f√©vrier 2026)

**Branche `main`** est √† jour avec tous les commits TREC :
```
743b689 chore: Update Docker configs and add HuggingFace deploy script
f0bf7ba feat(trec): Add TREC API endpoints to backend and documentation
b11f1b2 fix(config): Support both SYSCRED_LOAD_ML and SYSCRED_LOAD_ML_MODELS
d981b06 feat(trec): Integrate TRECRetriever into VerificationSystem
```

### Pour reprendre le travail

1. **Mettre √† jour votre copie locale :**
   ```bash
   cd /Users/bk280625/Desktop/systemFactChecking
   git fetch origin
   git pull origin main
   ```

2. **Synchroniser la branche feature (si vous y travaillez encore) :**
   ```bash
   git checkout feature/trec-88-90-integration
   git merge main
   git push origin feature/trec-88-90-integration
   ```

3. **Lancer le serveur SysCRED avec TREC :**
   ```bash
   cd 02_Code
   source venv/bin/activate
   SYSCRED_LOAD_ML_MODELS=false python -m syscred.backend_app
   ```
   Le serveur sera accessible sur http://127.0.0.1:5001

4. **Tester les endpoints TREC :**
   ```bash
   # Dans un autre terminal
   curl http://127.0.0.1:5001/api/trec/health
   curl http://127.0.0.1:5001/api/trec/corpus
   ```

### Fichiers cl√©s cr√©√©s/modifi√©s

| Fichier | Description |
|---------|-------------|
| `02_Code/syscred/backend_app.py` | Backend Flask avec endpoints TREC int√©gr√©s |
| `02_Code/syscred/trec_retriever.py` | Module de recherche d'√©vidences |
| `02_Code/syscred/eval_metrics.py` | M√©triques IR (MAP, NDCG, P@K) |
| `02_Code/demo_trec.py` | Script de d√©monstration CLI |
| `02_Code/demo_trec_web.py` | Serveur web de d√©mo l√©ger (port 5003) |
| `03_Docs/TREC_Integration_Documentation.md` | Cette documentation |

### Prochaines √©tapes sugg√©r√©es

- [ ] Int√©grer la recherche TREC dans l'interface frontend (index.html)
- [ ] Connecter avec un vrai corpus AP88-90 (pas juste le d√©mo)
- [ ] Ajouter les tests d'int√©gration automatis√©s
- [ ] D√©ployer sur Render/HuggingFace avec les nouveaux endpoints

---

*SysCRED v2.3 - TREC AP88-90 Integration*  
*(c) Dominique S. Loyer - PhD Thesis Prototype*
