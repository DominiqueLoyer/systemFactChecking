# Hybrid System for Verifying the Credibility of Information (Rules-based and AI-based)

## Please use these citation keys if you use the code  
[![Buy me a coffee](https://img.shields.io/badge/Buy%20me%20a%20coffee-FFDD00?logo=buy-me-a-coffee&logoColor=black)](https://www.buymeacoffee.com/dominiqueloyer)
[![Sponsor on GitHub](https://img.shields.io/badge/Sponsoriser-DominiqueLoyer-EA4AAA?logo=github-sponsors)](https://github.com/sponsors/DominiqueLoyer)
[![DOI](https://zenodo.org/badge/992891582.svg)](https://doi.org/10.5281/zenodo.17943226)


# Fact Checking System: Information Credibility Verification

Hybrid system combining predicate logic rules with machine learning for automated fact checking and information credibility assessment.

## Overview

This project implements a neuro-symbolic AI system that combines:
- **Predicate Logic:** Rule-based knowledge representation and reasoning
- **Machine Learning:** Neural networks for pattern recognition
- **OWL Ontologies:** Formal knowledge modeling with RDF/Turtle

The system assesses information source credibility, detects misinformation, and provides explainable verdicts on claim veracity.

## Features

- Hybrid predicate logic + ML architecture
- OWL 2 DL ontology for domain modeling
- Rule-based fact verification engine
- Neural classification of credibility indicators
- Sentiment analysis and bias detection
- Source reputation scoring
- Automatic credibility classification (High/Medium/Low)
- Explainable AI (XAI) for transparency

## Installation

```bash
pip install rdflib owlready2 scikit-learn torch nltk pandas numpy
```




