{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# SysCRED - Système Neuro-Symbolique de Vérification de Crédibilité\n",
                "\n",
                "**PhD Thesis Prototype** - Dominique S. Loyer  \n",
                "*Citation Key: loyerModelingHybridSystem2025*\n",
                "\n",
                "Ce notebook intègre:\n",
                "- Moteur de recherche TREC (BM25, QLD, TF-IDF)\n",
                "- Analyse NLP avec Transformers (GPU/TPU)\n",
                "- Ontologie RDF pour l'explicabilité\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DominiqueLoyer/syscred/blob/main/syscred_colab.ipynb)\n",
                "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/DominiqueLoyer/syscred/blob/main/syscred_kaggle.ipynb)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "env_config"
            },
            "source": [
                "## 1. Configuration de l'Environnement Colab"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "gpu_check"
            },
            "outputs": [],
            "source": [
                "# === Vérification GPU/TPU (Colab) ===\n",
                "import torch\n",
                "import subprocess\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Suppress TensorFlow warnings\n",
                "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
                "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"SysCRED - Google Colab Environment Check\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Check for GPU\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "    DEVICE = 'cuda'\n",
                "else:\n",
                "    print(\"✗ No GPU - using CPU\")\n",
                "    print(\"  → Runtime > Change runtime type > GPU pour activer\")\n",
                "    DEVICE = 'cpu'\n",
                "\n",
                "# Check for TPU (Colab)\n",
                "try:\n",
                "    import torch_xla.core.xla_model as xm\n",
                "    print(f\"✓ TPU available\")\n",
                "    DEVICE = xm.xla_device()\n",
                "except:\n",
                "    pass\n",
                "\n",
                "print(f\"\\nDevice: {DEVICE}\")\n",
                "\n",
                "# Colab-specific: Check if running in Colab\n",
                "IN_COLAB = 'google.colab' in sys.modules\n",
                "print(f\"Running in Colab: {IN_COLAB}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install_deps"
            },
            "outputs": [],
            "source": [
                "# === Installation des dépendances ===\n",
                "!pip install transformers[torch] datasets accelerate evaluate -q\n",
                "!pip install pyserini rdflib pytrec_eval nltk beautifulsoup4 python-whois -q\n",
                "\n",
                "# NLTK resources\n",
                "import nltk\n",
                "nltk.download('stopwords', quiet=True)\n",
                "nltk.download('punkt', quiet=True)\n",
                "nltk.download('punkt_tab', quiet=True)\n",
                "nltk.download('wordnet', quiet=True)\n",
                "\n",
                "print(\"✓ Dépendances installées\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "mount_drive"
            },
            "outputs": [],
            "source": [
                "# === (Optionnel) Monter Google Drive pour sauvegarder les résultats ===\n",
                "# Décommenter si vous voulez sauvegarder les résultats sur Drive\n",
                "\n",
                "# from google.colab import drive\n",
                "# drive.mount('/content/drive')\n",
                "# OUTPUT_DIR = '/content/drive/MyDrive/SysCRED_Results'\n",
                "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "# print(f\"✓ Results will be saved to: {OUTPUT_DIR}\")\n",
                "\n",
                "OUTPUT_DIR = '/content/syscred_results'\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "print(f\"✓ Output directory: {OUTPUT_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "modules"
            },
            "source": [
                "## 2. Modules SysCRED"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "ir_engine"
            },
            "outputs": [],
            "source": [
                "# === IR Engine (extrait de TREC_AP88-90) ===\n",
                "import re\n",
                "import math\n",
                "from typing import Dict, List, Tuple, Optional, Any\n",
                "from dataclasses import dataclass\n",
                "from collections import Counter\n",
                "\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.stem import PorterStemmer\n",
                "from nltk.tokenize import word_tokenize\n",
                "\n",
                "@dataclass\n",
                "class SearchResult:\n",
                "    doc_id: str\n",
                "    score: float\n",
                "    rank: int\n",
                "    snippet: Optional[str] = None\n",
                "\n",
                "class IREngine:\n",
                "    \"\"\"Moteur IR avec BM25, QLD, TF-IDF (Citation: loyerEvaluationModelesRecherche2025)\"\"\"\n",
                "    \n",
                "    BM25_K1 = 0.9\n",
                "    BM25_B = 0.4\n",
                "    \n",
                "    def __init__(self, use_stemming: bool = True):\n",
                "        self.stopwords = set(stopwords.words('english'))\n",
                "        self.stemmer = PorterStemmer() if use_stemming else None\n",
                "        self.searcher = None\n",
                "    \n",
                "    def preprocess(self, text: str) -> str:\n",
                "        \"\"\"Prétraitement avec stemming Porter.\"\"\"\n",
                "        if not isinstance(text, str):\n",
                "            return \"\"\n",
                "        tokens = word_tokenize(text.lower())\n",
                "        filtered = [t for t in tokens if t.isalpha() and t not in self.stopwords]\n",
                "        if self.stemmer:\n",
                "            filtered = [self.stemmer.stem(t) for t in filtered]\n",
                "        return ' '.join(filtered)\n",
                "    \n",
                "    def calculate_bm25(self, query_terms: List[str], doc_terms: List[str],\n",
                "                       doc_length: int, avg_doc_length: float,\n",
                "                       doc_freq: Dict[str, int], corpus_size: int) -> float:\n",
                "        \"\"\"Calcul BM25.\"\"\"\n",
                "        doc_counts = Counter(doc_terms)\n",
                "        score = 0.0\n",
                "        for term in query_terms:\n",
                "            if term not in doc_counts:\n",
                "                continue\n",
                "            tf = doc_counts[term]\n",
                "            df = doc_freq.get(term, 1)\n",
                "            idf = math.log((corpus_size - df + 0.5) / (df + 0.5) + 1)\n",
                "            num = tf * (self.BM25_K1 + 1)\n",
                "            den = tf + self.BM25_K1 * (1 - self.BM25_B + self.BM25_B * doc_length / avg_doc_length)\n",
                "            score += idf * (num / den)\n",
                "        return score\n",
                "    \n",
                "    def pseudo_relevance_feedback(self, query: str, top_docs: List[str], n_terms: int = 10) -> str:\n",
                "        \"\"\"Expansion de requête par PRF.\"\"\"\n",
                "        query_tokens = self.preprocess(query).split()\n",
                "        expansion = Counter()\n",
                "        for doc in top_docs:\n",
                "            for token in self.preprocess(doc).split():\n",
                "                if token not in query_tokens:\n",
                "                    expansion[token] += 1\n",
                "        expansion_terms = [t for t, _ in expansion.most_common(n_terms)]\n",
                "        return query + ' ' + ' '.join(expansion_terms)\n",
                "\n",
                "# Test\n",
                "ir = IREngine()\n",
                "print(\"Test preprocess:\", ir.preprocess(\"Information Retrieval systems help find documents\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "seo_analyzer"
            },
            "outputs": [],
            "source": [
                "# === SEO Analyzer ===\n",
                "class SEOAnalyzer:\n",
                "    \"\"\"Analyse SEO avec TF-IDF, BM25, PageRank estimé.\"\"\"\n",
                "    \n",
                "    BM25_K1 = 1.5\n",
                "    BM25_B = 0.75\n",
                "    \n",
                "    STOPWORDS = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\n",
                "                 'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',\n",
                "                 'le', 'la', 'les', 'un', 'une', 'des', 'du', 'de', 'et', 'ou'}\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.avg_doc_length = 500\n",
                "        self.corpus_size = 1000\n",
                "    \n",
                "    def tokenize(self, text: str) -> List[str]:\n",
                "        if not text:\n",
                "            return []\n",
                "        tokens = re.findall(r'\\b[a-zA-Z]{2,}\\b', text.lower())\n",
                "        return [t for t in tokens if t not in self.STOPWORDS]\n",
                "    \n",
                "    def calculate_tf_idf(self, text: str) -> Dict[str, float]:\n",
                "        tokens = self.tokenize(text)\n",
                "        if not tokens:\n",
                "            return {}\n",
                "        counts = Counter(tokens)\n",
                "        total = len(tokens)\n",
                "        tf_idf = {}\n",
                "        for term, count in counts.items():\n",
                "            tf = count / total\n",
                "            idf = math.log(self.corpus_size / (1 + len(term)))  # Simplified IDF\n",
                "            tf_idf[term] = tf * idf\n",
                "        return tf_idf\n",
                "    \n",
                "    def estimate_pagerank(self, domain_age_days: int = None, source_reputation: str = None) -> float:\n",
                "        d = 0.85\n",
                "        base = 1 - d\n",
                "        contrib = 0\n",
                "        if domain_age_days and domain_age_days > 365*5:\n",
                "            contrib += 0.3\n",
                "        elif domain_age_days and domain_age_days > 365*2:\n",
                "            contrib += 0.2\n",
                "        if source_reputation == 'High':\n",
                "            contrib += 0.3\n",
                "        elif source_reputation == 'Medium':\n",
                "            contrib += 0.15\n",
                "        return min(1.0, base + d * contrib)\n",
                "\n",
                "# Test\n",
                "seo = SEOAnalyzer()\n",
                "print(\"TF-IDF top terms:\", sorted(seo.calculate_tf_idf(\"credibility verification system\").items(), \n",
                "                                  key=lambda x: x[1], reverse=True)[:3])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "nlp_section"
            },
            "source": [
                "## 3. NLP avec Transformers (GPU/TPU)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "load_models"
            },
            "outputs": [],
            "source": [
                "# === Chargement des modèles NLP ===\n",
                "from transformers import pipeline\n",
                "\n",
                "print(\"Chargement des modèles NLP sur\", DEVICE, \"...\")\n",
                "\n",
                "# Sentiment Analysis\n",
                "sentiment_analyzer = pipeline(\n",
                "    \"sentiment-analysis\",\n",
                "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
                "    device=0 if DEVICE == 'cuda' else -1\n",
                ")\n",
                "\n",
                "# Named Entity Recognition\n",
                "ner_model = pipeline(\n",
                "    \"ner\",\n",
                "    model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
                "    aggregation_strategy=\"simple\",\n",
                "    device=0 if DEVICE == 'cuda' else -1\n",
                ")\n",
                "\n",
                "print(\"✓ Modèles chargés\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "test_nlp"
            },
            "outputs": [],
            "source": [
                "# === Test NLP ===\n",
                "test_text = \"According to researchers at Harvard University, the new study published in Nature shows significant results.\"\n",
                "\n",
                "print(\"Text:\", test_text)\n",
                "print(\"\\nSentiment:\", sentiment_analyzer(test_text)[0])\n",
                "print(\"\\nEntities:\")\n",
                "for ent in ner_model(test_text):\n",
                "    print(f\"  - {ent['word']}: {ent['entity_group']} ({ent['score']:.2f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "verification"
            },
            "source": [
                "## 4. Système de Vérification de Crédibilité"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "syscred_class"
            },
            "outputs": [],
            "source": [
                "# === SysCRED - Système complet ===\n",
                "from datetime import datetime\n",
                "\n",
                "class SysCRED:\n",
                "    \"\"\"Système neuro-symbolique de vérification de crédibilité.\"\"\"\n",
                "    \n",
                "    WEIGHTS = {\n",
                "        'source_reputation': 0.25,\n",
                "        'domain_age': 0.10,\n",
                "        'sentiment_neutrality': 0.15,\n",
                "        'entity_presence': 0.15,\n",
                "        'coherence': 0.15,\n",
                "        'fact_check': 0.20\n",
                "    }\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.ir_engine = IREngine()\n",
                "        self.seo_analyzer = SEOAnalyzer()\n",
                "        self.sentiment = sentiment_analyzer\n",
                "        self.ner = ner_model\n",
                "    \n",
                "    def verify(self, text: str, source_reputation: str = 'Unknown', domain_age_days: int = 0) -> Dict:\n",
                "        \"\"\"Vérifier la crédibilité d'un texte.\"\"\"\n",
                "        scores = {}\n",
                "        \n",
                "        # 1. Source reputation\n",
                "        rep_map = {'High': 1.0, 'Medium': 0.6, 'Low': 0.3, 'Unknown': 0.5}\n",
                "        scores['source_reputation'] = rep_map.get(source_reputation, 0.5)\n",
                "        \n",
                "        # 2. Domain age\n",
                "        if domain_age_days > 365*5:\n",
                "            scores['domain_age'] = 1.0\n",
                "        elif domain_age_days > 365*2:\n",
                "            scores['domain_age'] = 0.7\n",
                "        elif domain_age_days > 365:\n",
                "            scores['domain_age'] = 0.5\n",
                "        else:\n",
                "            scores['domain_age'] = 0.3\n",
                "        \n",
                "        # 3. Sentiment neutrality\n",
                "        sent = self.sentiment(text[:512])[0]\n",
                "        confidence = sent['score']\n",
                "        # Neutral = high credibility, extreme = lower\n",
                "        scores['sentiment_neutrality'] = 1 - abs(confidence - 0.5) * 2\n",
                "        \n",
                "        # 4. Entity presence (sources, institutions)\n",
                "        entities = self.ner(text[:512])\n",
                "        credible_entities = sum(1 for e in entities if e['entity_group'] in ['ORG', 'PER'])\n",
                "        scores['entity_presence'] = min(1.0, credible_entities * 0.2)\n",
                "        \n",
                "        # 5. Text coherence (based on preprocessing)\n",
                "        preprocessed = self.ir_engine.preprocess(text)\n",
                "        unique_ratio = len(set(preprocessed.split())) / max(1, len(preprocessed.split()))\n",
                "        scores['coherence'] = unique_ratio\n",
                "        \n",
                "        # 6. Fact check (placeholder - would use external API)\n",
                "        scores['fact_check'] = 0.5  # Neutral by default\n",
                "        \n",
                "        # Calculate weighted score\n",
                "        overall = sum(scores[k] * self.WEIGHTS[k] for k in self.WEIGHTS)\n",
                "        \n",
                "        # Determine level\n",
                "        if overall >= 0.7:\n",
                "            level = 'HIGH'\n",
                "        elif overall >= 0.4:\n",
                "            level = 'MEDIUM'\n",
                "        else:\n",
                "            level = 'LOW'\n",
                "        \n",
                "        return {\n",
                "            'score': round(overall, 3),\n",
                "            'level': level,\n",
                "            'components': {k: round(v, 3) for k, v in scores.items()},\n",
                "            'sentiment': sent,\n",
                "            'entities': entities[:5],\n",
                "            'timestamp': datetime.now().isoformat()\n",
                "        }\n",
                "\n",
                "# Initialize\n",
                "syscred = SysCRED()\n",
                "print(\"✓ SysCRED initialized\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "test_syscred"
            },
            "outputs": [],
            "source": [
                "# === Test SysCRED ===\n",
                "test_texts = [\n",
                "    {\n",
                "        'text': \"According to a study published by Harvard University in the journal Science, researchers have discovered a new method for detecting misinformation.\",\n",
                "        'source': 'High',\n",
                "        'age': 3650\n",
                "    },\n",
                "    {\n",
                "        'text': \"SHOCKING!!! You won't BELIEVE what scientists found! This changes EVERYTHING!!!\",\n",
                "        'source': 'Unknown',\n",
                "        'age': 30\n",
                "    }\n",
                "]\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"SysCRED - Tests de Vérification\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Store last result for use in next cell\n",
                "last_result = None\n",
                "\n",
                "for i, test in enumerate(test_texts, 1):\n",
                "    print(f\"\\n--- Test {i} ---\")\n",
                "    print(f\"Text: {test['text'][:80]}...\")\n",
                "    \n",
                "    last_result = syscred.verify(\n",
                "        text=test['text'],\n",
                "        source_reputation=test['source'],\n",
                "        domain_age_days=test['age']\n",
                "    )\n",
                "    \n",
                "    print(f\"\\nScore: {last_result['score']} ({last_result['level']})\")\n",
                "    print(\"Components:\")\n",
                "    for k, v in last_result['components'].items():\n",
                "        print(f\"  {k}: {v}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "rdf_section"
            },
            "source": [
                "## 5. Ontologie RDF (Explicabilité)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "rdf_save"
            },
            "outputs": [],
            "source": [
                "# === Sauvegarde des résultats en RDF ===\n",
                "from rdflib import Graph, Namespace, Literal, URIRef\n",
                "from rdflib.namespace import RDF, RDFS, XSD\n",
                "\n",
                "CRED = Namespace(\"http://example.org/credibility#\")\n",
                "\n",
                "def save_to_ontology(result: Dict, text_id: str) -> Graph:\n",
                "    \"\"\"Convertir un résultat de vérification en triplets RDF.\"\"\"\n",
                "    g = Graph()\n",
                "    g.bind('cred', CRED)\n",
                "    \n",
                "    eval_uri = CRED[f\"Evaluation_{text_id}\"]\n",
                "    \n",
                "    g.add((eval_uri, RDF.type, CRED.CredibilityEvaluation))\n",
                "    g.add((eval_uri, CRED.hasScore, Literal(result['score'], datatype=XSD.float)))\n",
                "    g.add((eval_uri, CRED.hasLevel, Literal(result['level'], datatype=XSD.string)))\n",
                "    g.add((eval_uri, CRED.timestamp, Literal(result['timestamp'], datatype=XSD.dateTime)))\n",
                "    \n",
                "    for comp_name, comp_value in result['components'].items():\n",
                "        comp_uri = CRED[f\"{text_id}_{comp_name}\"]\n",
                "        g.add((eval_uri, CRED.hasComponent, comp_uri))\n",
                "        g.add((comp_uri, CRED.componentName, Literal(comp_name)))\n",
                "        g.add((comp_uri, CRED.componentScore, Literal(comp_value, datatype=XSD.float)))\n",
                "    \n",
                "    return g\n",
                "\n",
                "# Create a test result if last_result is not defined\n",
                "if 'last_result' not in dir() or last_result is None:\n",
                "    print(\"Creating test result for RDF demo...\")\n",
                "    last_result = syscred.verify(\n",
                "        text=\"A study by MIT researchers shows promising results.\",\n",
                "        source_reputation='High',\n",
                "        domain_age_days=2000\n",
                "    )\n",
                "\n",
                "# Test\n",
                "g = save_to_ontology(last_result, \"test_001\")\n",
                "print(f\"Triplets RDF générés: {len(g)}\")\n",
                "print(g.serialize(format='turtle')[:500])\n",
                "\n",
                "# Save to file\n",
                "rdf_file = f\"{OUTPUT_DIR}/syscred_results.ttl\"\n",
                "g.serialize(destination=rdf_file, format='turtle')\n",
                "print(f\"\\n✓ Saved to: {rdf_file}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "notes"
            },
            "source": [
                "---\n",
                "\n",
                "## Notes\n",
                "\n",
                "- **GPU**: Runtime > Change runtime type > GPU\n",
                "- **Google Drive**: Décommenter la cellule 'mount_drive' pour sauvegarder sur Drive\n",
                "- **Citation**: loyerModelingHybridSystem2025, loyerEvaluationModelesRecherche2025\n",
                "\n",
                "### Synchronisation\n",
                "- **GitHub**: https://github.com/DominiqueLoyer/syscred\n",
                "- **Kaggle**: Même notebook disponible sur Kaggle\n",
                "- **Colab**: Ouvrir directement depuis GitHub avec le badge ci-dessus"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}